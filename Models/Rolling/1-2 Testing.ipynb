{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0730441a-ccf9-442a-92c9-c5d04df06bd8",
   "metadata": {},
   "source": [
    "## Embeddings for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "382cc984-3102-460e-ac08-9aa08b072796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, LSTM, Dense, Flatten, Concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "303e6c96-a8f3-493b-9eb9-4e1c3e20e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1) Configuration and Data Loading\n",
    "# ------------------------------------------------------------\n",
    "DB_NAME = \"../../copy_nba_box_scores.db\"\n",
    "DB_URI = f\"sqlite:///{DB_NAME}\"\n",
    "engine = create_engine(DB_URI, echo=False)\n",
    "\n",
    "# Example: Another table or CSV that has team-level defensive stats\n",
    "# E.g. columns: TEAM_ID, TEAM_DEF_RATING, TEAM_NAME, etc.\n",
    "# For demonstration, we'll assume we have a \"team_stats\" table in the same DB.\n",
    "team_stats_df = pd.read_sql(\"SELECT * FROM team_stats\", engine)\n",
    "\n",
    "# Main DataFrame: for each player's game-level data\n",
    "df = pd.read_sql(\"SELECT * FROM combined_player_game_data\", engine)\n",
    "\n",
    "# Ensure chronological order by player\n",
    "df = df.sort_values(by=[\"PLAYER_ID\", \"GAME_DATE_EST\"])\n",
    "\n",
    "# Example: convert MIN from \"XX:YY\" -> integer representing \"YY\"\n",
    "df[\"MIN\"] = df[\"MIN\"].apply(lambda x: int(x.split(\":\")[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92d58cac-5dc9-416b-8f60-9a80c4d637b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 2) Load Data & Sort\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_sql(\"SELECT * FROM combined_player_game_data\", engine)\n",
    "\n",
    "# Ensure data is sorted by player and date\n",
    "df = df.sort_values(by=[\"PLAYER_ID\", \"GAME_DATE_EST\"])\n",
    "\n",
    "# Extract the part after the colon and convert to int\n",
    "df['MIN'] = df['MIN'].apply(lambda x: int(x.split(':')[1]))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2a) Create Rolling Averages (Example: 3-game and 5-game windows)\n",
    "# ------------------------------------------------------------\n",
    "# We demonstrate using PTS, MIN, USG_PCT as sample columns to create rolling averages.\n",
    "# You can add more columns or different window sizes as you like.\n",
    "columns_to_roll = [\"PTS\", \"MIN\", \"USG_PCT\"]\n",
    "window_sizes = [3, 5]\n",
    "\n",
    "for col in columns_to_roll:\n",
    "    for w in window_sizes:\n",
    "        df[f\"{col}_rolling_{w}\"] = (\n",
    "            df.groupby(\"PLAYER_ID\")[col]\n",
    "              .transform(lambda x: x.shift(1).rolling(w).mean())\n",
    "        )\n",
    "\n",
    "# Fill any NaN values (early games won't have enough history for rolling windows)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Feature & Target Definitions\n",
    "# ------------------------------------------------------------\n",
    "numeric_features = [\n",
    "    \"PLAYER_ID\",\n",
    "    \"TEAM_ID\",\n",
    "    # \"PTS\",\n",
    "    \"MIN\",       # Minutes played\n",
    "    \"FGA\",       # Field Goal Attempts\n",
    "    \"FGM\",       # Field Goals Made\n",
    "    \"FG_PCT\",    # Field Goal Percentage\n",
    "    \"FG3A\",      # 3-Point Attempts\n",
    "    \"FG3M\",      # 3-Point Makes\n",
    "    \"FG3_PCT\",   # 3-Point Percentage\n",
    "    \"FTA\",       # Free Throw Attempts\n",
    "    \"FTM\",       # Free Throws Made\n",
    "    \"FT_PCT\",    # Free Throw Percentage\n",
    "    \"OREB\",\n",
    "    \"DREB\",\n",
    "    \"AST\",\n",
    "    \"USG_PCT\",\n",
    "    \"TS_PCT\",\n",
    "    \"STL\",\n",
    "    \"BLK\",\n",
    "    \"TO\",\n",
    "    \"PLUS_MINUS\",\n",
    "    \"E_OFF_RATING\", \n",
    "    \"OFF_RATING\", \n",
    "    \"E_DEF_RATING\", \n",
    "    \"DEF_RATING\", \n",
    "    \"E_NET_RATING\", \n",
    "    \"NET_RATING\", \n",
    "    \"AST_PCT\", \n",
    "    \"AST_TOV\", \n",
    "    \"AST_RATIO\", \n",
    "    \"OREB_PCT\", \n",
    "    \"DREB_PCT\", \n",
    "    \"REB_PCT\", \n",
    "    \"TM_TOV_PCT\", \n",
    "    \"EFG_PCT\", \n",
    "    \"TS_PCT\", \n",
    "    \"USG_PCT\", \n",
    "    \"E_USG_PCT\", \n",
    "    \"E_PACE\", \n",
    "    \"PACE\", \n",
    "    \"PACE_PER40\", \n",
    "    \"POSS\", \n",
    "    \"PIE\",\n",
    "    \"HOME_TEAM_ID\",\n",
    "    \"VISITOR_TEAM_ID\",\n",
    "    # New rolling features:\n",
    "    \"PTS_rolling_3\",\n",
    "    \"PTS_rolling_5\",\n",
    "    \"MIN_rolling_3\",\n",
    "    \"MIN_rolling_5\",\n",
    "    \"USG_PCT_rolling_3\",\n",
    "    \"USG_PCT_rolling_5\",\n",
    "]\n",
    "target_col = \"PTS\"\n",
    "\n",
    "df = df.dropna(subset=features + [target, \"PLAYER_NAME\"])\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d16da0-26c7-452d-afcc-b0b3ca6f27d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_numeric shape: (145838, 10, 51)\n",
      "y_train shape: (145838,)\n",
      "X_val_numeric shape: (34883, 10, 51)\n",
      "y_val shape: (34883,)\n",
      "train_player_id shape: (145838, 1)\n",
      "train_team_id shape: (145838, 1)\n",
      "train_opp_id shape: (145838, 1)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " player_id_input (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " team_id_input (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " opp_team_id_input (InputLayer)  [(None, 1)]         0           []                               \n",
      "                                                                                                  \n",
      " numeric_input (InputLayer)     [(None, 10, 51)]     0           []                               \n",
      "                                                                                                  \n",
      " player_embedding (Embedding)   (None, 1, 32)        24832       ['player_id_input[0][0]']        \n",
      "                                                                                                  \n",
      " team_embedding (Embedding)     (None, 1, 16)        496         ['team_id_input[0][0]']          \n",
      "                                                                                                  \n",
      " opp_team_embedding (Embedding)  (None, 1, 16)       496         ['opp_team_id_input[0][0]']      \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64)           29696       ['numeric_input[0][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 32)           0           ['player_embedding[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 16)           0           ['team_embedding[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 16)           0           ['opp_team_embedding[0][0]']     \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, 128)          0           ['lstm[0][0]',                   \n",
      "                                                                  'flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           8256        ['concat_layer[0][0]']           \n",
      "                                                                                                  \n",
      " pred_pts (Dense)               (None, 1)            65          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 63,841\n",
      "Trainable params: 63,841\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "4558/4558 [==============================] - 19s 4ms/step - loss: 26.1378 - mae: 3.4697 - val_loss: 23.1716 - val_mae: 3.4250\n",
      "Epoch 2/50\n",
      "4558/4558 [==============================] - 16s 3ms/step - loss: 21.6813 - mae: 3.0466 - val_loss: 20.5783 - val_mae: 2.8980\n",
      "Epoch 3/50\n",
      "4558/4558 [==============================] - 16s 3ms/step - loss: 20.9845 - mae: 2.9273 - val_loss: 20.0562 - val_mae: 2.8573\n",
      "Epoch 4/50\n",
      "4558/4558 [==============================] - 16s 3ms/step - loss: 20.5852 - mae: 2.8708 - val_loss: 19.5964 - val_mae: 2.7796\n",
      "Epoch 5/50\n",
      "4558/4558 [==============================] - 16s 3ms/step - loss: 20.2367 - mae: 2.8291 - val_loss: 19.8674 - val_mae: 2.8401\n",
      "Epoch 6/50\n",
      "4558/4558 [==============================] - 16s 3ms/step - loss: 19.9365 - mae: 2.7947 - val_loss: 19.1925 - val_mae: 2.6959\n",
      "Epoch 7/50\n",
      "1968/4558 [===========>..................] - ETA: 8s - loss: 19.2888 - mae: 2.7359 "
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 6) Create a Fixed-Window Sequence Function\n",
    "#    (for time-series numeric input)\n",
    "# ------------------------------------------------------------\n",
    "def create_fixed_window_sequences(\n",
    "    data: pd.DataFrame,\n",
    "    numeric_cols: list,\n",
    "    target_col: str,\n",
    "    player_col: str,\n",
    "    window_size: int\n",
    "):\n",
    "    \"\"\"\n",
    "    For each player, generate sliding windows of length `window_size`.\n",
    "    If i < window_size, we skip that row.\n",
    "    \n",
    "    Returns:\n",
    "      X_numeric: shape (num_samples, window_size, num_numeric_features)\n",
    "      y:         shape (num_samples,)\n",
    "      idx_list:  indices of the original rows used for the target\n",
    "    \"\"\"\n",
    "    X_list, y_list, idx_list = [], [], []\n",
    "    \n",
    "    for p_id, group in data.groupby(player_col):\n",
    "        group_features = group[numeric_cols].values  # (num_games, num_features)\n",
    "        group_target = group[target_col].values\n",
    "        group_idx = group.index\n",
    "        \n",
    "        # Slide over the group\n",
    "        for i in range(window_size, len(group_features)):\n",
    "            X_window = group_features[i - window_size : i]\n",
    "            y_value = group_target[i]\n",
    "            idx_val = group_idx[i]\n",
    "            \n",
    "            X_list.append(X_window)\n",
    "            y_list.append(y_value)\n",
    "            idx_list.append(idx_val)\n",
    "    \n",
    "    X_numeric = np.array(X_list, dtype=np.float32)\n",
    "    y_array = np.array(y_list, dtype=np.float32)\n",
    "    idx_array = np.array(idx_list)\n",
    "    \n",
    "    return X_numeric, y_array, idx_array\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7) Train / Validation Split\n",
    "#    (Simple example, not season-based. We'll do 80/20.)\n",
    "# ------------------------------------------------------------\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "\n",
    "# We will scale numeric features. Fit only on train set, then transform val.\n",
    "scaler = MinMaxScaler()\n",
    "train_df_scaled = train_df.copy()\n",
    "val_df_scaled = val_df.copy()\n",
    "\n",
    "train_df_scaled[numeric_features] = scaler.fit_transform(train_df[numeric_features])\n",
    "val_df_scaled[numeric_features]   = scaler.transform(val_df[numeric_features])\n",
    "\n",
    "# Choose a window size\n",
    "window_size = 10\n",
    "\n",
    "# Create time-series numeric arrays\n",
    "X_train_numeric, y_train, train_idx = create_fixed_window_sequences(\n",
    "    train_df_scaled, \n",
    "    numeric_cols=numeric_features,\n",
    "    target_col=target_col,\n",
    "    player_col=\"PLAYER_ID\",\n",
    "    window_size=window_size\n",
    ")\n",
    "X_val_numeric, y_val, val_idx = create_fixed_window_sequences(\n",
    "    val_df_scaled,\n",
    "    numeric_cols=numeric_features,\n",
    "    target_col=target_col,\n",
    "    player_col=\"PLAYER_ID\",\n",
    "    window_size=window_size\n",
    ")\n",
    "\n",
    "print(\"X_train_numeric shape:\", X_train_numeric.shape)  # (num_samples, window_size, num_features)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val_numeric shape:\", X_val_numeric.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) Prepare Embedding Inputs\n",
    "# ------------------------------------------------------------\n",
    "# We need integer ID arrays for:\n",
    "#   - PLAYER_ID\n",
    "#   - TEAM_ID\n",
    "#   - OPP_TEAM_ID\n",
    "# But note, each row in the final X_train_numeric corresponds to some row in the original df.\n",
    "# We'll gather IDs from the original data at those indices.\n",
    "#\n",
    "# Because each \"sample\" in X_train_numeric is a window of 10 rows from the same player, we\n",
    "# only need the \"final row's\" IDs. So let's do that simply:\n",
    "\n",
    "def gather_ids_for_samples(df_original, idx_array):\n",
    "    \"\"\"\n",
    "    Given indices from the final row in the time series,\n",
    "    return arrays for player_id, team_id, opp_team_id.\n",
    "    \"\"\"\n",
    "    player_ids = df_original.loc[idx_array, \"PLAYER_ID\"].values\n",
    "    team_ids   = df_original.loc[idx_array, \"TEAM_ID\"].values\n",
    "    opp_ids    = df_original.loc[idx_array, \"VISITOR_TEAM_ID\"].values\n",
    "    return player_ids.astype(int), team_ids.astype(int), opp_ids.astype(int)\n",
    "\n",
    "train_player_id, train_team_id, train_opp_id = gather_ids_for_samples(train_df, train_idx)\n",
    "val_player_id, val_team_id, val_opp_id       = gather_ids_for_samples(val_df, val_idx)\n",
    "\n",
    "# For embeddings, we usually want them as shape (num_samples, 1)\n",
    "train_player_id = train_player_id.reshape(-1, 1)\n",
    "train_team_id   = train_team_id.reshape(-1, 1)\n",
    "train_opp_id    = train_opp_id.reshape(-1, 1)\n",
    "\n",
    "val_player_id = val_player_id.reshape(-1, 1)\n",
    "val_team_id   = val_team_id.reshape(-1, 1)\n",
    "val_opp_id    = val_opp_id.reshape(-1, 1)\n",
    "\n",
    "print(\"train_player_id shape:\", train_player_id.shape)\n",
    "print(\"train_team_id shape:\", train_team_id.shape)\n",
    "print(\"train_opp_id shape:\", train_opp_id.shape)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9) Build a Multi-Input Model with Embeddings\n",
    "# ------------------------------------------------------------\n",
    "NUM_PLAYERS = df[\"PLAYER_ID\"].nunique()\n",
    "NUM_TEAMS   = df[\"TEAM_ID\"].nunique()\n",
    "\n",
    "# Decide on embedding dimensions\n",
    "EMBED_DIM_PLAYER = 32\n",
    "EMBED_DIM_TEAM   = 16\n",
    "\n",
    "# 1) Time-series numeric input: shape = (window_size, len(numeric_features))\n",
    "input_numeric = Input(shape=(window_size, len(numeric_features)), name=\"numeric_input\")\n",
    "x = LSTM(64, return_sequences=False)(input_numeric)  \n",
    "# shape now (batch, 64)\n",
    "\n",
    "# 2) Player ID input: shape = (None, 1)\n",
    "input_player = Input(shape=(1,), name=\"player_id_input\")\n",
    "embed_player = Embedding(\n",
    "    input_dim=NUM_PLAYERS + 1,  # +1 in case IDs go up to N\n",
    "    output_dim=EMBED_DIM_PLAYER,\n",
    "    name=\"player_embedding\"\n",
    ")(input_player)\n",
    "embed_player = Flatten()(embed_player)  # shape (batch, EMBED_DIM_PLAYER)\n",
    "\n",
    "# 3) Team ID input\n",
    "input_team = Input(shape=(1,), name=\"team_id_input\")\n",
    "embed_team = Embedding(\n",
    "    input_dim=NUM_TEAMS + 1,\n",
    "    output_dim=EMBED_DIM_TEAM,\n",
    "    name=\"team_embedding\"\n",
    ")(input_team)\n",
    "embed_team = Flatten()(embed_team)  # shape (batch, EMBED_DIM_TEAM)\n",
    "\n",
    "# 4) Opponent Team ID input\n",
    "input_opp = Input(shape=(1,), name=\"opp_team_id_input\")\n",
    "embed_opp = Embedding(\n",
    "    input_dim=NUM_TEAMS + 1,\n",
    "    output_dim=EMBED_DIM_TEAM,\n",
    "    name=\"opp_team_embedding\"\n",
    ")(input_opp)\n",
    "embed_opp = Flatten()(embed_opp)\n",
    "\n",
    "# 5) Concatenate all\n",
    "merged = Concatenate(name=\"concat_layer\")([x, embed_player, embed_team, embed_opp])\n",
    "\n",
    "# 6) Dense layers -> output\n",
    "hidden = Dense(64, activation=\"relu\")(merged)\n",
    "output = Dense(1, activation=\"linear\", name=\"pred_pts\")(hidden)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[input_numeric, input_player, input_team, input_opp],\n",
    "    outputs=output\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 10) Train the Model\n",
    "# ------------------------------------------------------------\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    x={\n",
    "       \"numeric_input\": X_train_numeric,\n",
    "       \"player_id_input\": train_player_id,\n",
    "       \"team_id_input\": train_team_id,\n",
    "       \"opp_team_id_input\": train_opp_id\n",
    "    },\n",
    "    y=y_train,\n",
    "    validation_data=(\n",
    "        {\n",
    "            \"numeric_input\": X_val_numeric,\n",
    "            \"player_id_input\": val_player_id,\n",
    "            \"team_id_input\": val_team_id,\n",
    "            \"opp_team_id_input\": val_opp_id\n",
    "        },\n",
    "        y_val\n",
    "    ),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 11) Evaluate\n",
    "# ------------------------------------------------------------\n",
    "y_pred = model.predict({\n",
    "    \"numeric_input\": X_val_numeric,\n",
    "    \"player_id_input\": val_player_id,\n",
    "    \"team_id_input\": val_team_id,\n",
    "    \"opp_team_id_input\": val_opp_id\n",
    "}).flatten()\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Validation MAE:  {mae:.3f}\")\n",
    "print(f\"Validation RMSE: {rmse:.3f}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 12) Optional: Build a DataFrame of Predictions\n",
    "# ------------------------------------------------------------\n",
    "val_results_df = val_df.loc[val_idx, [\"PLAYER_ID\", \"PLAYER_NAME\", target_col]].copy()\n",
    "val_results_df[\"Predicted_PTS\"] = y_pred\n",
    "val_results_df.rename(columns={target_col: \"Actual_PTS\"}, inplace=True)\n",
    "\n",
    "# Sort or manipulate as desired\n",
    "val_results_df.sort_values(by=\"Predicted_PTS\", ascending=False, inplace=True)\n",
    "\n",
    "print(val_results_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20def0db-d1bb-4042-93a3-65d84ac45557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_NBA",
   "language": "python",
   "name": "gpu_nba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
