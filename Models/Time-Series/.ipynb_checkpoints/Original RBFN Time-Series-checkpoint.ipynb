{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf6863f-8209-4cb0-8fe9-5fc6a9b5c0d6",
   "metadata": {},
   "source": [
    "## RBFNs (Radial Basis Function Networks) - Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f77a821-c571-473f-9f96-88f9ab9ceb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bdddf4e-9197-43b3-aaa8-b2ef5fbdfb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1) Custom RBF Layer\n",
    "# ------------------------------------------------------------\n",
    "class RBFLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, gamma=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        features = input_shape[-1]\n",
    "        self.centers = self.add_weight(\n",
    "            name='centers',\n",
    "            shape=(self.units, features),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.betas = self.add_weight(\n",
    "            name='betas',\n",
    "            shape=(self.units,),\n",
    "            initializer='ones',\n",
    "            trainable=True\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        expanded_inputs = tf.expand_dims(inputs, axis=1)\n",
    "        expanded_centers = tf.expand_dims(self.centers, axis=0)\n",
    "        distances = tf.reduce_sum(tf.square(expanded_inputs - expanded_centers), axis=-1)\n",
    "        rbfs = tf.exp(-self.gamma * tf.expand_dims(self.betas, 0) * distances)\n",
    "        return rbfs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58aedc16-d84d-4609-a722-aa423c3ca48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 2) Configuration\n",
    "# ------------------------------------------------------------\n",
    "DB_NAME = \"../../nba_data.db\"\n",
    "DB_URI = f\"sqlite:///{DB_NAME}\"\n",
    "engine = create_engine(DB_URI, echo=False)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Load Data & Sort\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_sql(\"SELECT * FROM player_game_features\", engine)\n",
    "\n",
    "# Ensure data is sorted by player and date\n",
    "df = df.sort_values(by=[\"player_id\", \"game_date\"])\n",
    "\n",
    "# Extract the season or year from 'game_date'\n",
    "df['game_year'] = pd.to_datetime(df['game_date']).dt.year\n",
    "\n",
    "# Features and target\n",
    "features = [\"player_id\", \"pts\", \"min\", \"fgm\", \"fga\", \"pts_per_min\", \"fg_pct\"]\n",
    "target = \"pts\"\n",
    "\n",
    "df = df.dropna(subset=features + [target])\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35223764-bf9c-4546-83cc-5537b02df21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4) Helper Function: Create Sequences\n",
    "# ------------------------------------------------------------\n",
    "def create_player_sequences_fixed_length(data, target, player_column, max_length):\n",
    "    \"\"\"\n",
    "    Create sequences of all past games for each player, then pad them to 'max_length'.\n",
    "    \"\"\"\n",
    "    X_list, y_list = [], []\n",
    "    \n",
    "    for p_id, group in data.groupby(player_column):\n",
    "        player_features = group.drop(columns=[player_column]).values\n",
    "        player_target = target[group.index].values\n",
    "\n",
    "        # Build sequences from length=1 up to the current index\n",
    "        for i in range(1, len(player_features)):\n",
    "            seq = player_features[:i]  # up to i-1\n",
    "            X_list.append(seq)\n",
    "            y_list.append(player_target[i])  # target at i\n",
    "\n",
    "    num_features = X_list[0].shape[1] if X_list else 0\n",
    "    X_padded = np.zeros((len(X_list), max_length, num_features), dtype=np.float32)\n",
    "\n",
    "    for i, seq in enumerate(X_list):\n",
    "        seq_len = len(seq)\n",
    "        if seq_len <= max_length:\n",
    "            X_padded[i, max_length - seq_len:, :] = seq\n",
    "        else:\n",
    "            X_padded[i, :, :] = seq[-max_length:]\n",
    "\n",
    "    return X_padded, np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4941b8d4-6986-4c0c-9616-520e147048e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 5) RBF Model Builder\n",
    "# ------------------------------------------------------------\n",
    "def build_rbf_model(input_dim, rbf_units=20, gamma=1.0):\n",
    "    \"\"\"\n",
    "    Build a simple RBF Network:\n",
    "      - Flattened input -> RBF layer -> Dense(1)\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(RBFLayer(units=rbf_units, gamma=gamma, input_shape=(input_dim,)))\n",
    "    # Output\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7303a58f-506e-405c-ae06-503c12fafe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 51.8652 - mae: 5.4347 - val_loss: 58.4465 - val_mae: 5.6343\n",
      "Epoch 2/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 37.3717 - mae: 4.7578 - val_loss: 57.3453 - val_mae: 5.4976\n",
      "Epoch 3/50\n",
      "5823/5823 [==============================] - 7s 1ms/step - loss: 36.5735 - mae: 4.6973 - val_loss: 50.1039 - val_mae: 5.2998\n",
      "Epoch 4/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 36.0221 - mae: 4.6577 - val_loss: 51.2409 - val_mae: 5.2568\n",
      "Epoch 5/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 35.7432 - mae: 4.6350 - val_loss: 49.7981 - val_mae: 5.1960\n",
      "Epoch 6/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 35.4990 - mae: 4.6171 - val_loss: 47.9932 - val_mae: 5.1491\n",
      "Epoch 7/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 35.3097 - mae: 4.6018 - val_loss: 48.4422 - val_mae: 5.1425\n",
      "Epoch 8/50\n",
      "5823/5823 [==============================] - 7s 1ms/step - loss: 35.1984 - mae: 4.5947 - val_loss: 48.5953 - val_mae: 5.1257\n",
      "Epoch 9/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 35.1092 - mae: 4.5863 - val_loss: 45.8889 - val_mae: 5.0883\n",
      "Epoch 10/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 35.0113 - mae: 4.5796 - val_loss: 48.2637 - val_mae: 5.0993\n",
      "Epoch 11/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 34.8922 - mae: 4.5693 - val_loss: 48.9320 - val_mae: 5.1154\n",
      "Epoch 12/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 34.8175 - mae: 4.5635 - val_loss: 45.6224 - val_mae: 5.2921\n",
      "Epoch 13/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 34.7563 - mae: 4.5583 - val_loss: 51.2845 - val_mae: 5.2012\n",
      "Epoch 14/50\n",
      "5823/5823 [==============================] - 7s 1ms/step - loss: 34.7062 - mae: 4.5554 - val_loss: 48.7365 - val_mae: 5.0979\n",
      "Epoch 15/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 34.6285 - mae: 4.5504 - val_loss: 44.8147 - val_mae: 5.0156\n",
      "Epoch 16/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 34.6359 - mae: 4.5497 - val_loss: 45.7959 - val_mae: 5.0061\n",
      "Epoch 17/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 34.5449 - mae: 4.5436 - val_loss: 45.8717 - val_mae: 5.0171\n",
      "Epoch 18/50\n",
      "5823/5823 [==============================] - 8s 1ms/step - loss: 34.5609 - mae: 4.5434 - val_loss: 44.3951 - val_mae: 4.9961\n",
      "Epoch 19/50\n",
      "5823/5823 [==============================] - 7s 1ms/step - loss: 34.5171 - mae: 4.5397 - val_loss: 44.8724 - val_mae: 4.9905\n",
      "Epoch 20/50\n",
      "5823/5823 [==============================] - 7s 1ms/step - loss: 34.4900 - mae: 4.5352 - val_loss: 43.7018 - val_mae: 4.9996\n",
      "Epoch 21/50\n",
      "5823/5823 [==============================] - 7s 1ms/step - loss: 34.4878 - mae: 4.5382 - val_loss: 45.7423 - val_mae: 5.0137\n",
      "Epoch 22/50\n",
      "5823/5823 [==============================] - 7s 1ms/step - loss: 34.4948 - mae: 4.5374 - val_loss: 48.5394 - val_mae: 5.0845\n",
      "Epoch 23/50\n",
      "5823/5823 [==============================] - 7s 1ms/step - loss: 34.4306 - mae: 4.5319 - val_loss: 45.0621 - val_mae: 4.9752\n",
      "Epoch 24/50\n",
      "5823/5823 [==============================] - 7s 1ms/step - loss: 34.3656 - mae: 4.5262 - val_loss: 53.8600 - val_mae: 5.3125\n",
      "Epoch 25/50\n",
      "5823/5823 [==============================] - 7s 1ms/step - loss: 34.3860 - mae: 4.5274 - val_loss: 47.4516 - val_mae: 5.0457\n",
      "430/430 [==============================] - 0s 535us/step\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 6) Train on 2015-2022, Validate on 2023\n",
    "# ------------------------------------------------------------\n",
    "train_mask = (df['game_year'] >= 2015) & (df['game_year'] <= 2022)\n",
    "val_mask   = (df['game_year'] == 2023)\n",
    "\n",
    "train_data = df[train_mask]\n",
    "val_data   = df[val_mask]\n",
    "\n",
    "# If there's no data in either split, raise an error or handle gracefully\n",
    "if len(train_data) == 0 or len(val_data) == 0:\n",
    "    raise ValueError(\"No data found in train or validation sets with the specified year filters.\")\n",
    "\n",
    "# Scale only feature columns except \"player_id\"\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features_train = scaler.fit_transform(train_data[features].drop(columns=[\"player_id\"]))\n",
    "scaled_features_val   = scaler.transform(val_data[features].drop(columns=[\"player_id\"]))\n",
    "\n",
    "train_scaled = pd.DataFrame(scaled_features_train, index=train_data.index, columns=features[1:])\n",
    "train_scaled[\"player_id\"] = train_data[\"player_id\"].values\n",
    "\n",
    "val_scaled = pd.DataFrame(scaled_features_val, index=val_data.index, columns=features[1:])\n",
    "val_scaled[\"player_id\"] = val_data[\"player_id\"].values\n",
    "\n",
    "def find_player_longest_sequence(data_df, id_col=\"player_id\"):\n",
    "    max_len = 0\n",
    "    for _, group in data_df.groupby(id_col):\n",
    "        length = len(group)\n",
    "        # Subtract 1 because we build sequences up to (i-1)\n",
    "        max_len = max(max_len, length - 1)\n",
    "    return max_len\n",
    "\n",
    "max_len_train = find_player_longest_sequence(train_scaled, \"player_id\")\n",
    "max_len_val   = find_player_longest_sequence(val_scaled, \"player_id\")\n",
    "max_len_both  = max(max_len_train, max_len_val)\n",
    "if max_len_both < 1:\n",
    "    raise ValueError(\"Not enough data to create sequences.\")\n",
    "\n",
    "# Create sequences for RBF\n",
    "X_train_3D, y_train = create_player_sequences_fixed_length(\n",
    "    train_scaled, train_data[target], \"player_id\", max_len_both\n",
    ")\n",
    "X_val_3D, y_val = create_player_sequences_fixed_length(\n",
    "    val_scaled, val_data[target], \"player_id\", max_len_both\n",
    ")\n",
    "\n",
    "# Ensure we have data after sequence creation\n",
    "if len(X_train_3D) == 0 or len(X_val_3D) == 0:\n",
    "    raise ValueError(\"No sequences were created for training/validation.\")\n",
    "\n",
    "# RBFN requires 2D input: flatten [batch, timesteps, features] -> [batch, timesteps*features]\n",
    "X_train = X_train_3D.reshape((X_train_3D.shape[0], -1))\n",
    "X_val   = X_val_3D.reshape((X_val_3D.shape[0], -1))\n",
    "\n",
    "input_dim = X_train.shape[1]  # timesteps * features\n",
    "\n",
    "# Build the RBF model\n",
    "model = build_rbf_model(input_dim=input_dim, rbf_units=30, gamma=0.1)\n",
    "\n",
    "# Early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50, batch_size=32,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_val).flatten()\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c11a7ef3-f9f1-4948-9871-fae0eab233fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Year: 2023\n",
      "Train Years: 2015 to 2022\n",
      "MAE:  5.00\n",
      "RMSE: 6.61\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Year: 2023\")\n",
    "print(\"Train Years: 2015 to 2022\")\n",
    "print(f\"MAE:  {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_NBA",
   "language": "python",
   "name": "gpu_nba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
