{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4578d508-0613-4c47-8936-0d089d6edefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96400fad-6e63-49ea-b104-68c0c98855b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Configuration\n",
    "# ------------------------------------------------------------\n",
    "DB_NAME = \"nba_data.db\"\n",
    "DB_URI = f\"sqlite:///{DB_NAME}\"\n",
    "engine = create_engine(DB_URI, echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a706e575-4856-4a74-8d56-3f021bc4a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Load Data\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_sql(\"SELECT * FROM player_game_features\", engine)\n",
    "\n",
    "# Sort by player_id and game_date to maintain chronological order per player\n",
    "df = df.sort_values(by=[\"game_date\", \"player_id\"])\n",
    "\n",
    "\n",
    "# Extract the season or year from 'game_date'. \n",
    "# Assuming 'game_date' is in a format like \"YYYY-MM-DD\".\n",
    "df['game_year'] = pd.to_datetime(df['game_date']).dt.year\n",
    "\n",
    "# We'll use the same features as before\n",
    "features = [\n",
    "    \"rolling_pts_5\",\n",
    "    \"rolling_min_5\",\n",
    "    \"rolling_fg_pct_5\",\n",
    "    \"rolling_ppm_5\",\n",
    "    \"rolling_fgm_5\",\n",
    "    \"rolling_fga_5\",\n",
    "    \"reb\",\n",
    "    \"ast\",\n",
    "    \"pts\"\n",
    "]\n",
    "\n",
    "# Drop rows with NaNs in features or target\n",
    "df = df.dropna(subset=features + [\"pts\"])\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"pts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25f65ee-e22f-43d5-9811-9042e1331f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features for deep learning\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Time-based split: 80% training, 20% validation\n",
    "split_index = int(len(df) * 0.8)\n",
    "X_train, X_val = X_scaled[:split_index], X_scaled[split_index:]\n",
    "y_train, y_val = y.iloc[:split_index], y.iloc[split_index:]\n",
    "\n",
    "# Build a simple deep learning model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50, batch_size=32,\n",
    "    verbose=1, callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val).flatten()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print results\n",
    "print(\"Time-based validation results (Deep Learning):\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20d75d-abae-4e03-941d-33fe6c1f0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'Actual': y_val.values,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "# Display the first 10 rows\n",
    "print(results.head(10))\n",
    "\n",
    "# Optionally, save to CSV\n",
    "results.to_csv('predicted_vs_actual.csv', index=False)\n",
    "print(\"Results saved to 'predicted_vs_actual.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f2679-2181-4d7c-a906-e9735540ca3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4447d056-7878-43c2-abb6-0d6a95c3d40d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
