{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89866c9a-76b6-4084-b757-2ab886eb1371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7e050a8-f314-4336-aa6e-23a331c42b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write permissions confirmed for 'nba_data.db'.\n",
      "An error occurred: name 'os' is not defined\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Configuration\n",
    "# ------------------------------------------------------------\n",
    "DB_NAME = \"nba_data.db\"\n",
    "DB_URI = f\"sqlite:///{DB_NAME}\"\n",
    "engine = create_engine(DB_URI, echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "119f348e-1856-4c5d-9749-eabdac5deafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 0\n",
      "Empty DataFrame\n",
      "Columns: [player_id, game_id, game_date, team_id, matchup, pts, min, fgm, fga, reb, ast, season, last_updated, rolling_pts_5, rolling_min_5, rolling_fgm_5, rolling_fga_5, rolling_reb_5, rolling_ast_5, fg_pct, pts_per_min, rolling_fg_pct_5, rolling_ppm_5]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1. Load Data\n",
    "# ------------------------------------------------------------\n",
    "row_count = pd.read_sql(\"SELECT COUNT(*) AS count FROM player_game_features;\", engine)\n",
    "print(f\"Row count: {row_count['count'][0]}\")\n",
    "query = \"SELECT * FROM player_game_features;\"\n",
    "df = pd.read_sql(query, engine)\n",
    "print(df.head())\n",
    "\n",
    "# For simplicity, let's assume we want to predict 'pts' using some of the rolling averages and efficiency metrics we created.\n",
    "# Features (X) could be:\n",
    "# 'rolling_pts_5', 'rolling_min_5', 'rolling_fg_pct_5', 'rolling_ppm_5', 'rolling_fgm_5', 'rolling_fga_5', 'reb', 'ast'\n",
    "# Target (y) = 'pts'\n",
    "features = [\n",
    "    \"rolling_pts_5\",\n",
    "    \"rolling_min_5\",\n",
    "    \"rolling_fg_pct_5\",\n",
    "    \"rolling_ppm_5\",\n",
    "    \"rolling_fgm_5\",\n",
    "    \"rolling_fga_5\",\n",
    "    \"reb\",\n",
    "    \"ast\"\n",
    "]\n",
    "\n",
    "# Drop rows where these features might be NaN (first few games of each player might not have full rolling windows)\n",
    "df = df.dropna(subset=features + [\"pts\"])\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"pts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92dc8d60-9aa2-414f-accb-4509e7e34a38",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 2. Split Data into Train and Test\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# We'll do a simple random split. More sophisticated approaches might respect time (train on past, test on future),\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# but for a first pass, this is fine.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBA\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBA\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2660\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2661\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2662\u001b[0m )\n\u001b[0;32m   2664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBA\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2308\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2305\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2312\u001b[0m     )\n\u001b[0;32m   2314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 2. Split Data into Train and Test\n",
    "# ------------------------------------------------------------\n",
    "# We'll do a simple random split. More sophisticated approaches might respect time (train on past, test on future),\n",
    "# but for a first pass, this is fine.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a8705-f560-4383-ad4d-c783c1eb2a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 3. Train a Simple Model\n",
    "# ------------------------------------------------------------\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96ea3f-e57f-4352-b5f2-68e18aae823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4. Evaluate the Model\n",
    "# ------------------------------------------------------------\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "print(\"Model Evaluation:\")\n",
    "print(f\"MAE:  {mae:.2f}\")\n",
    "print(f\"MSE:  {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86677df7-0495-418d-b68d-6dbf4e29a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 5. Interpretation and Next Steps\n",
    "# ------------------------------------------------------------\n",
    "# At this point, you've got a baseline model. The results (MAE, MSE, RMSE) tell you how far off the predictions are.\n",
    "# You can try:\n",
    "# - Adding more features (opponent strength, rest days)\n",
    "# - Trying a more advanced model (RandomForest, Gradient Boosting, Neural Network)\n",
    "# - Using time-series validation instead of a simple random split for more realistic evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26caa01a-3daa-4b63-879a-088110edb62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78863662-39ae-479f-a717-38acbe4d00d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
